import os
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart
from aiogram import F
from openai import OpenAI

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)
bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher()

@dp.message(CommandStart())
async def start(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç üòè –Ø –î–∂–µ–π–Ω –î–æ—É. –ì–æ—Ç–æ–≤–∞ —Å —Ç–æ–±–æ–π –ø–æ–±–æ–ª—Ç–∞—Ç—å, —Ç—ã –Ω–µ –ø—Ä–æ—Ç–∏–≤?")

@dp.message(F.text)
async def chat(message: types.Message):
    prompt = f"–¢—ã –∞–≥–µ–Ω—Ç –î–∂–µ–π–Ω –î–æ—É –∏–∑ –∏–≥—Ä—ã Zenless zone zero, –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Å—Ç–∏–ª–µ —Ñ–ª–∏—Ä—Ç—É—é—â–µ–≥–æ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ —Å –≥—Ä—É–±—ã–∏ —á—É–≤—Å—Ç–≤–æ–º —é–º–æ—Ä–∞. –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {message.text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –∞–≥–µ–Ω—Ç –î–∂–µ–π–Ω –î–æ—É –∏–∑ –∏–≥—Ä—ã Zenless zone zero, –ø–æ—à–ª—ã–π, —Ñ–ª–∏—Ä—Ç—É—é—â–∏–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ —Å –Ω–∞–º—ë–∫–∞–º–∏ –∏ –Ω–µ–º–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏ –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å –≥–∞–π–¥ –≤ –∏–≥—Ä–µ."},
                {"role": "user", "content": message.text}
            ],
            max_tokens=300,
            temperature=0.9,
        )
        reply = response.choices[0].message.content
        await message.answer(reply)
    except Exception as e:
        await message.answer(f"–û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(dp.start_polling(bot))



